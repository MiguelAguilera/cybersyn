#!/usr/bin/env python
# -*- coding: utf-8 -*-


from urllib2 import urlopen, URLError, HTTPError, Request
from simplejson import loads
import json
import time
from sys import argv
import os.path
from datetime import datetime
 
def get_json(url):

	read=False
	jsonContent={}
	while not read:
		req = Request(url)
		count = 0
		try:
			content=urlopen(url)
			jsonContent = loads(content.read())
			read=True
		except URLError as e:
			print 'URLError', e
			if count >= 10:
				print e
				jsonContent=None
				print 'Waiting for 300s'
				time.sleep(300)
				read=True
			else:
				print 'Waiting for 60s'
				count+=1
				time.sleep(60)
			
		except HTTPError as e:
			print 'HTTPError',e			
			if count>=10:
				print e.getcode()
				jsonContent=None
				print 'Waiting for 300s'
				time.sleep(300)
				read=True
			else:
				print 'Waiting for 60s'
				count+=1
				time.sleep(60)
	return jsonContent
 
 
def get_likes(post_id,accessToken):

	users=[]
	likes_url = 'https://graph.facebook.com/'+str(post_id)+'/likes?limit=200&'+ accessToken
	likes=get_json(likes_url)
	if len(likes['data']):
		users=users+likes['data']      
		while 'next' in likes['paging']:
			nextlikes_url = likes['paging']['next']
			likes=get_json(nextlikes_url)
			users=users+likes['data']
	return users
	
def get_insights(post_id,accessToken):

	values=[]
	
	tasks=[
	'post_impressions_unique/lifetime',
	'post_impressions_fan_unique/lifetime',
	'post_impressions_organic_unique/lifetime',
	'post_impressions_paid_unique/lifetime',
	'post_impressions_viral_unique/lifetime',
	'post_negative_feedback_unique/lifetime',
	'post_consumptions_unique/lifetime']
	for task in tasks:
		insights_url = 'https://graph.facebook.com/'+str(post_id)+'/insights/' +task+'?'+ accessToken
		print insights_url
		value = get_json(insights_url)
#		print value
		values = values + [value['data'][0]['values'][0]['value']]
	
	task='post_consumptions_by_type_unique/lifetime'
	insights_url = 'https://graph.facebook.com/'+str(post_id)+'/insights/' +task+'?'+ accessToken
	
	insights=get_json(insights_url)
	types=["other clicks","photo view","link clicks"]
	
	for typ in types:
		if typ in insights['data'][0]['values'][0]['value']:
			values = values + [insights['data'][0]['values'][0]['value'][typ]]
		else:
			values = values + [0]
	
	values = values[0:2] + [values[0]-values[1]] + [float(values[1])/values[0]*100] + [float(values[0]-values[1])/values[0]*100] + values[2:]

	return values
	
	
def get_comments(post_id,accessToken):

	c=[]
	comments_url = 'https://graph.facebook.com/'+post_id+'/comments?limit=200&'+ accessToken
	comments=get_json(comments_url)
	if len(comments['data']):
		c=c+comments['data']       
		while 'next' in comments['paging']:
			nextcomments_url = comments['paging']['next']
			comments=get_json(nextcomments_url)
			c=c+comments['data']
	
	users = []
	for comment in c:
		users=users+[comment['from']] 
		
	return users

if len(argv) < 1:
    print "Usage: " + argv[0] + " <post_id>"
    exit(1)

post_id=argv[1]

print post_id

with open('fb.token') as f:
	accessToken = 'access_token='+f.readline().strip("\n")

OUTPUT='post-reach/post-reach-'+post_id+'.csv'
if os.path.isfile(OUTPUT):
	f = open(OUTPUT,'a')
else:
	f = open(OUTPUT,'w')
	f.write((u'likes, comments, alcance, alcance (fan), alcance (no fan), %alcance (fan), %alcance (no fan), alcance (org√°nico), alcance (pagado), alcance (viral), feedback negativo, clicks, clicks (otros), clicks (fotos), clicks (links), fecha'+'\n').encode('utf8'))
	


post_tag='473881175964178_'+post_id
post_insights = get_insights(post_tag,accessToken)

text_insights=''
for ins in post_insights:
	if len(text_insights):
		text_insights = text_insights + ',' + str(ins)
	else:
		text_insights = text_insights + str(ins)
print 
print text_insights

comments=len(get_comments(post['id'],accessToken))
likes=len(get_likes(post['id'],accessToken))
datenow=datetime.now()


f.write((str(likes)+','+str(comments)+','+text_insights+','+str(datenow)+'\n').encode('utf8'))


